{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Graph Convolutional Networks for Semi Supervised Node Classification</h2>\n",
    "\n",
    "This code extends https://github.com/tkipf/gcn to visualize, in real time how the karate club node embeddings change during semi-supervised training, when only one point from each community is labelled.\n",
    "\n",
    "references: <br>\n",
    "https://en.wikipedia.org/wiki/Zachary%27s_karate_club<br>\n",
    "https://arxiv.org/abs/1609.02907<br>\n",
    "http://tkipf.github.io/graph-convolutional-networks/<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "from utils import normalize, sparse_mx_to_torch_sparse_tensor, accuracy\n",
    "from scipy.sparse import csr_matrix, coo_matrix, diags,eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class graph_convolution_layer(Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(graph_convolution_layer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        self.weight.data.uniform_(-1, 1)\n",
    "        self.bias.data.uniform_(-1, 1)\n",
    "\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        return output + self.bias\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.gc1 = graph_convolution_layer(nfeat, nhid)\n",
    "        self.gc2 = graph_convolution_layer(nhid, nclass)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.sigmoid(self.gc1(x, adj))\n",
    "        embedding = x\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "       \n",
    "        x = self.gc2(x, adj)\n",
    "        return embedding, F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x195608e2070>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "epochs = 500\n",
    "lr = 0.01\n",
    "weight_decay = 5e-4\n",
    "hidden = 2 # A hidden size of 2! -> this is the x and y axis for the node embedding visualization\n",
    "dropout = 0.5\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading karate club dataset...\n",
      "Dataset has 34 nodes, 78 edges, 34 features, 5 classes\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Load karate club dataset\"\"\"\n",
    "print('Loading karate club dataset...')\n",
    "\n",
    "path=\"data/karate_club/\"\n",
    "\n",
    "edges = np.loadtxt(\"{}edges.txt\".format(path), dtype=np.int32) - 1  # 0-based indexing\n",
    "features = eye(np.max(edges+1), dtype=np.float32).tocsr()\n",
    "idx_labels = np.loadtxt(\"{}mod-based-clusters.txt\".format(path), dtype=np.int32)\n",
    "idx_labels = idx_labels[idx_labels[:, 0].argsort()]\n",
    "\n",
    "labels = idx_labels[:, 1]\n",
    "classes = np.unique(labels)\n",
    "one_hot_classes = dict(zip(classes, np.squeeze(np.eye(len(classes))[list(range(len(classes)))])))\n",
    "one_hot_labels = np.array([one_hot_classes[i] for i in labels])\n",
    "\n",
    "adj = coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                    shape=(labels.shape[0], labels.shape[0]), dtype=np.float32)\n",
    "\n",
    "# build symmetric adjacency matrix\n",
    "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "\n",
    "adj = normalize(adj + eye(adj.shape[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Dataset has {} nodes, {} edges, {} features, {} classes'.format(adj.shape[0], edges.shape[0], features.shape[1],5))\n",
    "\n",
    "\n",
    "idx_train = [0, 2, 4, 8] # Labelling one point from each community/class!\n",
    "idx_val = range(0, len(labels))\n",
    "idx_test = range(0, len(labels))\n",
    "\n",
    "features = torch.FloatTensor(np.array(features.todense()))\n",
    "labels = torch.LongTensor(np.where(one_hot_labels)[1])\n",
    "adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "\n",
    "idx_train = torch.LongTensor(idx_train)\n",
    "idx_val = torch.LongTensor(idx_val)\n",
    "idx_test = torch.LongTensor(idx_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (gc1): graph_convolution_layer()\n",
      "  (gc2): graph_convolution_layer()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model and optimizer\n",
    "model = GCN(nfeat=features.shape[1], nhid=hidden, nclass=labels.max().item() + 1, dropout=dropout)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 1.4594 time: 0.5096s\n",
      "Epoch: 0002 loss_train: 1.2891 time: 0.5947s\n",
      "Epoch: 0003 loss_train: 1.5205 time: 0.6117s\n",
      "Epoch: 0004 loss_train: 1.3924 time: 0.6113s\n",
      "Epoch: 0005 loss_train: 1.2763 time: 0.8026s\n",
      "Epoch: 0006 loss_train: 1.4293 time: 0.9054s\n",
      "Epoch: 0007 loss_train: 1.3136 time: 1.0889s\n",
      "Epoch: 0008 loss_train: 1.4225 time: 0.9347s\n",
      "Epoch: 0009 loss_train: 1.2076 time: 0.8147s\n",
      "Epoch: 0010 loss_train: 1.4864 time: 0.6499s\n",
      "Epoch: 0011 loss_train: 1.5138 time: 0.6641s\n",
      "Epoch: 0012 loss_train: 1.3796 time: 0.6598s\n",
      "Epoch: 0013 loss_train: 1.4106 time: 0.5790s\n",
      "Epoch: 0014 loss_train: 1.3457 time: 0.5949s\n",
      "Epoch: 0015 loss_train: 1.3062 time: 0.5685s\n",
      "Epoch: 0016 loss_train: 1.3834 time: 0.6647s\n",
      "Epoch: 0017 loss_train: 1.4501 time: 0.5920s\n",
      "Epoch: 0018 loss_train: 1.4153 time: 0.5810s\n",
      "Epoch: 0019 loss_train: 1.3356 time: 0.6430s\n",
      "Epoch: 0020 loss_train: 1.5039 time: 0.6046s\n",
      "Epoch: 0021 loss_train: 1.2610 time: 0.5968s\n",
      "Epoch: 0022 loss_train: 1.3833 time: 0.6064s\n",
      "Epoch: 0023 loss_train: 1.2125 time: 0.5251s\n",
      "Epoch: 0024 loss_train: 1.5553 time: 0.6403s\n",
      "Epoch: 0025 loss_train: 1.3658 time: 0.5564s\n",
      "Epoch: 0026 loss_train: 1.2375 time: 0.6883s\n",
      "Epoch: 0027 loss_train: 1.3701 time: 0.5896s\n",
      "Epoch: 0028 loss_train: 1.3229 time: 0.5906s\n",
      "Epoch: 0029 loss_train: 1.3538 time: 0.6295s\n",
      "Epoch: 0030 loss_train: 1.3321 time: 0.5472s\n",
      "Epoch: 0031 loss_train: 1.3818 time: 0.5659s\n",
      "Epoch: 0032 loss_train: 1.2546 time: 0.6187s\n",
      "Epoch: 0033 loss_train: 1.3894 time: 0.5844s\n",
      "Epoch: 0034 loss_train: 1.4059 time: 0.5215s\n",
      "Epoch: 0035 loss_train: 1.3918 time: 0.8211s\n",
      "Epoch: 0036 loss_train: 1.5046 time: 0.5759s\n",
      "Epoch: 0037 loss_train: 1.3914 time: 0.5363s\n",
      "Epoch: 0038 loss_train: 1.3610 time: 0.8152s\n",
      "Epoch: 0039 loss_train: 1.3080 time: 0.6234s\n",
      "Epoch: 0040 loss_train: 1.3376 time: 0.6450s\n",
      "Epoch: 0041 loss_train: 1.3801 time: 0.6372s\n",
      "Epoch: 0042 loss_train: 1.3333 time: 0.6273s\n",
      "Epoch: 0043 loss_train: 1.1379 time: 0.5410s\n",
      "Epoch: 0044 loss_train: 1.2782 time: 0.5731s\n",
      "Epoch: 0045 loss_train: 1.4956 time: 0.8133s\n",
      "Epoch: 0046 loss_train: 1.3073 time: 0.7210s\n",
      "Epoch: 0047 loss_train: 1.4849 time: 1.0801s\n",
      "Epoch: 0048 loss_train: 1.2390 time: 0.9313s\n",
      "Epoch: 0049 loss_train: 1.2037 time: 0.7001s\n",
      "Epoch: 0050 loss_train: 1.2951 time: 0.6725s\n",
      "Epoch: 0051 loss_train: 1.4055 time: 0.8582s\n",
      "Epoch: 0052 loss_train: 1.3902 time: 0.7472s\n",
      "Epoch: 0053 loss_train: 1.3067 time: 0.6123s\n",
      "Epoch: 0054 loss_train: 1.2822 time: 0.6519s\n",
      "Epoch: 0055 loss_train: 1.3161 time: 0.6181s\n",
      "Epoch: 0056 loss_train: 1.2221 time: 0.6046s\n",
      "Epoch: 0057 loss_train: 1.4433 time: 0.6858s\n",
      "Epoch: 0058 loss_train: 1.3889 time: 0.5883s\n",
      "Epoch: 0059 loss_train: 1.2639 time: 0.5856s\n",
      "Epoch: 0060 loss_train: 1.3480 time: 0.5911s\n",
      "Epoch: 0061 loss_train: 1.2283 time: 0.5786s\n",
      "Epoch: 0062 loss_train: 1.2637 time: 0.5732s\n",
      "Epoch: 0063 loss_train: 1.3671 time: 0.5959s\n",
      "Epoch: 0064 loss_train: 1.2830 time: 0.6824s\n",
      "Epoch: 0065 loss_train: 1.2532 time: 0.5664s\n",
      "Epoch: 0066 loss_train: 1.2308 time: 0.6002s\n",
      "Epoch: 0067 loss_train: 1.2790 time: 0.6113s\n",
      "Epoch: 0068 loss_train: 1.2941 time: 0.5829s\n",
      "Epoch: 0069 loss_train: 1.3391 time: 0.5989s\n",
      "Epoch: 0070 loss_train: 1.1792 time: 0.5590s\n",
      "Epoch: 0071 loss_train: 1.2963 time: 0.5897s\n",
      "Epoch: 0072 loss_train: 1.3447 time: 0.6504s\n",
      "Epoch: 0073 loss_train: 1.2341 time: 0.7127s\n",
      "Epoch: 0074 loss_train: 1.2156 time: 0.6041s\n",
      "Epoch: 0075 loss_train: 1.1305 time: 0.5771s\n",
      "Epoch: 0076 loss_train: 1.3748 time: 0.6134s\n",
      "Epoch: 0077 loss_train: 1.2510 time: 0.5834s\n",
      "Epoch: 0078 loss_train: 1.2926 time: 0.5782s\n",
      "Epoch: 0079 loss_train: 1.2470 time: 0.6083s\n",
      "Epoch: 0080 loss_train: 1.1395 time: 0.5416s\n",
      "Epoch: 0081 loss_train: 1.3739 time: 0.5837s\n",
      "Epoch: 0082 loss_train: 1.1615 time: 0.5472s\n",
      "Epoch: 0083 loss_train: 1.2885 time: 0.6647s\n",
      "Epoch: 0084 loss_train: 1.3423 time: 0.6496s\n",
      "Epoch: 0085 loss_train: 1.1280 time: 0.5482s\n",
      "Epoch: 0086 loss_train: 1.1350 time: 0.5972s\n",
      "Epoch: 0087 loss_train: 1.2851 time: 0.5894s\n",
      "Epoch: 0088 loss_train: 1.1212 time: 0.7906s\n",
      "Epoch: 0089 loss_train: 1.2348 time: 0.8064s\n",
      "Epoch: 0090 loss_train: 1.2118 time: 0.6934s\n",
      "Epoch: 0091 loss_train: 1.2884 time: 0.7022s\n",
      "Epoch: 0092 loss_train: 1.2047 time: 0.8289s\n",
      "Epoch: 0093 loss_train: 1.0976 time: 0.8351s\n",
      "Epoch: 0094 loss_train: 1.1662 time: 0.6711s\n",
      "Epoch: 0095 loss_train: 1.3439 time: 0.7163s\n",
      "Epoch: 0096 loss_train: 1.4102 time: 0.8435s\n",
      "Epoch: 0097 loss_train: 1.1232 time: 0.6990s\n",
      "Epoch: 0098 loss_train: 1.1486 time: 0.5607s\n",
      "Epoch: 0099 loss_train: 1.2130 time: 0.8412s\n",
      "Epoch: 0100 loss_train: 1.1494 time: 0.7299s\n",
      "Epoch: 0101 loss_train: 1.0882 time: 0.9237s\n",
      "Epoch: 0102 loss_train: 1.0671 time: 0.6589s\n",
      "Epoch: 0103 loss_train: 1.2253 time: 0.8783s\n",
      "Epoch: 0104 loss_train: 1.3081 time: 0.6887s\n",
      "Epoch: 0105 loss_train: 1.1009 time: 0.6060s\n",
      "Epoch: 0106 loss_train: 1.2740 time: 0.7170s\n",
      "Epoch: 0107 loss_train: 1.3822 time: 1.0502s\n",
      "Epoch: 0108 loss_train: 1.1933 time: 0.8286s\n",
      "Epoch: 0109 loss_train: 1.2531 time: 0.6361s\n",
      "Epoch: 0110 loss_train: 1.2767 time: 0.6087s\n",
      "Epoch: 0111 loss_train: 1.1329 time: 0.7204s\n",
      "Epoch: 0112 loss_train: 1.0990 time: 0.9329s\n",
      "Epoch: 0113 loss_train: 0.9788 time: 0.7099s\n",
      "Epoch: 0114 loss_train: 1.1564 time: 0.8294s\n",
      "Epoch: 0115 loss_train: 1.2534 time: 0.6486s\n",
      "Epoch: 0116 loss_train: 1.1535 time: 0.5953s\n",
      "Epoch: 0117 loss_train: 1.3213 time: 0.5416s\n",
      "Epoch: 0118 loss_train: 1.1512 time: 0.5773s\n",
      "Epoch: 0119 loss_train: 1.2014 time: 0.6043s\n",
      "Epoch: 0120 loss_train: 0.9488 time: 0.6172s\n",
      "Epoch: 0121 loss_train: 1.1984 time: 0.9302s\n",
      "Epoch: 0122 loss_train: 1.1671 time: 0.8453s\n",
      "Epoch: 0123 loss_train: 1.0653 time: 0.7532s\n",
      "Epoch: 0124 loss_train: 1.0263 time: 0.6078s\n",
      "Epoch: 0125 loss_train: 1.2081 time: 0.6033s\n",
      "Epoch: 0126 loss_train: 1.0236 time: 0.5850s\n",
      "Epoch: 0127 loss_train: 1.0530 time: 0.5477s\n",
      "Epoch: 0128 loss_train: 1.3911 time: 0.5880s\n",
      "Epoch: 0129 loss_train: 1.0633 time: 0.6496s\n",
      "Epoch: 0130 loss_train: 1.1852 time: 0.8309s\n",
      "Epoch: 0131 loss_train: 1.0875 time: 1.0875s\n",
      "Epoch: 0132 loss_train: 1.0743 time: 0.6197s\n",
      "Epoch: 0133 loss_train: 1.2734 time: 0.5809s\n",
      "Epoch: 0134 loss_train: 1.2370 time: 0.5350s\n",
      "Epoch: 0135 loss_train: 1.2898 time: 0.5489s\n",
      "Epoch: 0136 loss_train: 1.1342 time: 0.6091s\n",
      "Epoch: 0137 loss_train: 1.0367 time: 0.5687s\n",
      "Epoch: 0138 loss_train: 1.3442 time: 0.5788s\n",
      "Epoch: 0139 loss_train: 1.3467 time: 0.6124s\n",
      "Epoch: 0140 loss_train: 1.1334 time: 0.6345s\n",
      "Epoch: 0141 loss_train: 0.9998 time: 0.5538s\n",
      "Epoch: 0142 loss_train: 1.1612 time: 0.6843s\n",
      "Epoch: 0143 loss_train: 1.0091 time: 0.6482s\n",
      "Epoch: 0144 loss_train: 1.2767 time: 0.7150s\n",
      "Epoch: 0145 loss_train: 1.1736 time: 0.5497s\n",
      "Epoch: 0146 loss_train: 1.0153 time: 0.5842s\n",
      "Epoch: 0147 loss_train: 0.9623 time: 0.5581s\n",
      "Epoch: 0148 loss_train: 1.0598 time: 0.6151s\n",
      "Epoch: 0149 loss_train: 0.9717 time: 0.6231s\n",
      "Epoch: 0150 loss_train: 1.3347 time: 0.8492s\n",
      "Epoch: 0151 loss_train: 1.1495 time: 0.9391s\n",
      "Epoch: 0152 loss_train: 0.9863 time: 0.7348s\n",
      "Epoch: 0153 loss_train: 1.0687 time: 0.9608s\n",
      "Epoch: 0154 loss_train: 1.0597 time: 0.7679s\n",
      "Epoch: 0155 loss_train: 1.3598 time: 0.7525s\n",
      "Epoch: 0156 loss_train: 1.1122 time: 0.8306s\n",
      "Epoch: 0157 loss_train: 1.0720 time: 0.9813s\n",
      "Epoch: 0158 loss_train: 1.2215 time: 0.7140s\n",
      "Epoch: 0159 loss_train: 1.0849 time: 0.9642s\n",
      "Epoch: 0160 loss_train: 1.1861 time: 0.6137s\n",
      "Epoch: 0161 loss_train: 1.0411 time: 0.5346s\n",
      "Epoch: 0162 loss_train: 1.1513 time: 0.6620s\n",
      "Epoch: 0163 loss_train: 1.2550 time: 0.5861s\n",
      "Epoch: 0164 loss_train: 1.3984 time: 0.5440s\n",
      "Epoch: 0165 loss_train: 1.3185 time: 0.6180s\n",
      "Epoch: 0166 loss_train: 1.1469 time: 0.5773s\n",
      "Epoch: 0167 loss_train: 1.1481 time: 0.6150s\n",
      "Epoch: 0168 loss_train: 0.9660 time: 0.6176s\n",
      "Epoch: 0169 loss_train: 0.9738 time: 0.7100s\n",
      "Epoch: 0170 loss_train: 1.0473 time: 0.5440s\n",
      "Epoch: 0171 loss_train: 1.0182 time: 0.6046s\n",
      "Epoch: 0172 loss_train: 1.1023 time: 0.6258s\n",
      "Epoch: 0173 loss_train: 1.0962 time: 0.6278s\n",
      "Epoch: 0174 loss_train: 0.9863 time: 0.6396s\n",
      "Epoch: 0175 loss_train: 1.2135 time: 0.5986s\n",
      "Epoch: 0176 loss_train: 0.9701 time: 0.5871s\n",
      "Epoch: 0177 loss_train: 1.2118 time: 0.5780s\n",
      "Epoch: 0178 loss_train: 1.1209 time: 0.7699s\n",
      "Epoch: 0179 loss_train: 1.0309 time: 0.5595s\n",
      "Epoch: 0180 loss_train: 1.1612 time: 0.5626s\n",
      "Epoch: 0181 loss_train: 0.9443 time: 0.5824s\n",
      "Epoch: 0182 loss_train: 0.9367 time: 0.6735s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0183 loss_train: 1.1412 time: 0.5581s\n",
      "Epoch: 0184 loss_train: 0.8979 time: 0.6247s\n",
      "Epoch: 0185 loss_train: 1.0906 time: 0.5965s\n",
      "Epoch: 0186 loss_train: 1.4828 time: 0.6085s\n",
      "Epoch: 0187 loss_train: 0.9550 time: 0.6707s\n",
      "Epoch: 0188 loss_train: 1.1982 time: 0.7617s\n",
      "Epoch: 0189 loss_train: 0.9586 time: 0.5812s\n",
      "Epoch: 0190 loss_train: 1.1373 time: 0.6485s\n",
      "Epoch: 0191 loss_train: 1.1099 time: 0.5997s\n",
      "Epoch: 0192 loss_train: 0.9083 time: 0.5928s\n",
      "Epoch: 0193 loss_train: 1.2370 time: 0.6263s\n",
      "Epoch: 0194 loss_train: 0.8694 time: 0.5872s\n",
      "Epoch: 0195 loss_train: 1.0120 time: 0.6448s\n",
      "Epoch: 0196 loss_train: 1.1935 time: 0.5893s\n",
      "Epoch: 0197 loss_train: 0.9584 time: 0.7965s\n",
      "Epoch: 0198 loss_train: 1.0655 time: 0.6546s\n",
      "Epoch: 0199 loss_train: 0.8778 time: 0.6708s\n",
      "Epoch: 0200 loss_train: 0.9405 time: 0.6019s\n",
      "Epoch: 0201 loss_train: 0.8740 time: 0.6602s\n",
      "Epoch: 0202 loss_train: 1.1591 time: 0.6778s\n",
      "Epoch: 0203 loss_train: 0.9281 time: 0.5739s\n",
      "Epoch: 0204 loss_train: 1.0835 time: 0.5975s\n",
      "Epoch: 0205 loss_train: 0.7672 time: 0.7043s\n",
      "Epoch: 0206 loss_train: 1.1212 time: 0.6976s\n",
      "Epoch: 0207 loss_train: 0.9277 time: 0.5909s\n",
      "Epoch: 0208 loss_train: 1.0022 time: 0.5973s\n",
      "Epoch: 0209 loss_train: 0.8047 time: 0.6187s\n",
      "Epoch: 0210 loss_train: 1.1542 time: 0.6533s\n",
      "Epoch: 0211 loss_train: 1.0576 time: 0.5271s\n",
      "Epoch: 0212 loss_train: 0.8530 time: 0.5736s\n",
      "Epoch: 0213 loss_train: 1.2067 time: 0.6269s\n",
      "Epoch: 0214 loss_train: 1.0266 time: 0.9606s\n",
      "Epoch: 0215 loss_train: 0.8747 time: 0.9104s\n",
      "Epoch: 0216 loss_train: 1.1084 time: 0.7710s\n",
      "Epoch: 0217 loss_train: 1.0183 time: 0.7235s\n",
      "Epoch: 0218 loss_train: 0.7701 time: 0.6709s\n",
      "Epoch: 0219 loss_train: 0.7757 time: 0.6377s\n",
      "Epoch: 0220 loss_train: 0.9502 time: 0.6034s\n",
      "Epoch: 0221 loss_train: 1.0986 time: 0.6354s\n",
      "Epoch: 0222 loss_train: 0.9567 time: 0.6071s\n",
      "Epoch: 0223 loss_train: 0.9198 time: 0.6543s\n",
      "Epoch: 0224 loss_train: 0.9421 time: 0.9823s\n",
      "Epoch: 0225 loss_train: 0.8835 time: 1.0449s\n",
      "Epoch: 0226 loss_train: 0.9506 time: 0.8493s\n",
      "Epoch: 0227 loss_train: 0.9410 time: 0.9145s\n",
      "Epoch: 0228 loss_train: 1.0599 time: 0.8896s\n",
      "Epoch: 0229 loss_train: 0.9843 time: 0.9979s\n",
      "Epoch: 0230 loss_train: 0.9605 time: 0.8587s\n",
      "Epoch: 0231 loss_train: 1.1806 time: 0.6226s\n",
      "Epoch: 0232 loss_train: 1.0811 time: 0.7443s\n",
      "Epoch: 0233 loss_train: 1.0556 time: 0.7685s\n",
      "Epoch: 0234 loss_train: 0.9959 time: 0.7830s\n",
      "Epoch: 0235 loss_train: 1.0357 time: 0.8779s\n",
      "Epoch: 0236 loss_train: 0.9957 time: 0.8282s\n",
      "Epoch: 0237 loss_train: 1.2963 time: 0.7514s\n",
      "Epoch: 0238 loss_train: 1.2688 time: 0.9023s\n",
      "Epoch: 0239 loss_train: 1.1222 time: 0.8379s\n",
      "Epoch: 0240 loss_train: 0.8582 time: 0.6891s\n",
      "Epoch: 0241 loss_train: 0.8314 time: 0.5754s\n",
      "Epoch: 0242 loss_train: 0.9803 time: 0.5462s\n",
      "Epoch: 0243 loss_train: 0.7560 time: 0.6295s\n",
      "Epoch: 0244 loss_train: 1.0294 time: 0.6705s\n",
      "Epoch: 0245 loss_train: 0.8834 time: 0.5969s\n",
      "Epoch: 0246 loss_train: 1.1356 time: 0.6387s\n",
      "Epoch: 0247 loss_train: 0.7782 time: 0.8271s\n",
      "Epoch: 0248 loss_train: 0.8035 time: 0.6971s\n",
      "Epoch: 0249 loss_train: 1.0105 time: 0.6472s\n",
      "Epoch: 0250 loss_train: 0.7521 time: 0.7040s\n",
      "Epoch: 0251 loss_train: 1.1541 time: 0.7282s\n",
      "Epoch: 0252 loss_train: 0.8726 time: 0.6355s\n",
      "Epoch: 0253 loss_train: 1.2147 time: 0.5667s\n",
      "Epoch: 0254 loss_train: 0.9115 time: 0.7772s\n",
      "Epoch: 0255 loss_train: 1.0109 time: 0.6788s\n",
      "Epoch: 0256 loss_train: 0.9608 time: 0.8548s\n",
      "Epoch: 0257 loss_train: 1.0080 time: 0.9987s\n",
      "Epoch: 0258 loss_train: 0.7784 time: 0.8272s\n",
      "Epoch: 0259 loss_train: 0.7141 time: 0.6521s\n",
      "Epoch: 0260 loss_train: 0.8887 time: 0.5490s\n",
      "Epoch: 0261 loss_train: 0.8396 time: 0.5920s\n",
      "Epoch: 0262 loss_train: 0.9684 time: 0.5731s\n",
      "Epoch: 0263 loss_train: 1.1093 time: 0.7001s\n",
      "Epoch: 0264 loss_train: 0.8157 time: 0.6377s\n",
      "Epoch: 0265 loss_train: 1.0381 time: 0.6482s\n",
      "Epoch: 0266 loss_train: 0.7896 time: 0.6174s\n",
      "Epoch: 0267 loss_train: 0.9537 time: 0.6249s\n",
      "Epoch: 0268 loss_train: 0.9036 time: 0.5805s\n",
      "Epoch: 0269 loss_train: 0.8948 time: 0.6665s\n",
      "Epoch: 0270 loss_train: 0.7574 time: 0.5605s\n",
      "Epoch: 0271 loss_train: 1.2274 time: 0.6099s\n",
      "Epoch: 0272 loss_train: 0.7592 time: 0.9118s\n",
      "Epoch: 0273 loss_train: 0.9901 time: 0.6818s\n",
      "Epoch: 0274 loss_train: 0.9050 time: 0.6098s\n",
      "Epoch: 0275 loss_train: 0.8988 time: 0.6147s\n",
      "Epoch: 0276 loss_train: 0.7417 time: 0.6113s\n",
      "Epoch: 0277 loss_train: 1.0290 time: 0.7082s\n",
      "Epoch: 0278 loss_train: 0.8482 time: 0.5868s\n",
      "Epoch: 0279 loss_train: 0.9294 time: 0.6812s\n",
      "Epoch: 0280 loss_train: 0.9108 time: 0.8927s\n",
      "Epoch: 0281 loss_train: 0.8338 time: 0.7018s\n",
      "Epoch: 0282 loss_train: 0.9521 time: 0.8547s\n",
      "Epoch: 0283 loss_train: 0.7154 time: 0.8088s\n",
      "Epoch: 0284 loss_train: 0.9121 time: 0.6910s\n",
      "Epoch: 0285 loss_train: 0.8245 time: 0.6151s\n",
      "Epoch: 0286 loss_train: 0.8845 time: 0.6052s\n",
      "Epoch: 0287 loss_train: 1.0070 time: 0.7337s\n",
      "Epoch: 0288 loss_train: 1.0802 time: 0.6381s\n",
      "Epoch: 0289 loss_train: 1.4438 time: 0.6342s\n",
      "Epoch: 0290 loss_train: 0.8972 time: 0.7665s\n",
      "Epoch: 0291 loss_train: 1.2596 time: 0.8898s\n",
      "Epoch: 0292 loss_train: 1.0873 time: 0.8066s\n",
      "Epoch: 0293 loss_train: 0.8471 time: 0.6060s\n",
      "Epoch: 0294 loss_train: 0.9713 time: 0.6822s\n",
      "Epoch: 0295 loss_train: 1.4313 time: 0.6347s\n",
      "Epoch: 0296 loss_train: 0.8571 time: 0.6401s\n",
      "Epoch: 0297 loss_train: 1.1746 time: 0.5762s\n",
      "Epoch: 0298 loss_train: 0.8193 time: 0.6506s\n",
      "Epoch: 0299 loss_train: 0.9115 time: 0.7034s\n",
      "Epoch: 0300 loss_train: 0.7008 time: 0.8698s\n",
      "Epoch: 0301 loss_train: 1.2936 time: 0.7657s\n",
      "Epoch: 0302 loss_train: 0.8286 time: 0.8007s\n",
      "Epoch: 0303 loss_train: 0.8532 time: 0.7030s\n",
      "Epoch: 0304 loss_train: 0.9321 time: 0.6938s\n",
      "Epoch: 0305 loss_train: 0.8799 time: 0.6214s\n",
      "Epoch: 0306 loss_train: 1.2873 time: 0.5494s\n",
      "Epoch: 0307 loss_train: 0.7264 time: 0.5866s\n",
      "Epoch: 0308 loss_train: 0.8733 time: 0.4930s\n",
      "Epoch: 0309 loss_train: 0.9082 time: 0.6918s\n",
      "Epoch: 0310 loss_train: 1.1074 time: 0.7155s\n",
      "Epoch: 0311 loss_train: 1.0794 time: 0.6819s\n",
      "Epoch: 0312 loss_train: 0.9381 time: 0.7007s\n",
      "Epoch: 0313 loss_train: 0.9474 time: 0.6264s\n",
      "Epoch: 0314 loss_train: 0.7816 time: 0.6579s\n",
      "Epoch: 0315 loss_train: 1.1469 time: 0.6479s\n",
      "Epoch: 0316 loss_train: 0.9341 time: 0.5889s\n",
      "Epoch: 0317 loss_train: 1.0922 time: 0.5528s\n",
      "Epoch: 0318 loss_train: 0.9676 time: 0.5876s\n",
      "Epoch: 0319 loss_train: 0.8112 time: 0.8279s\n",
      "Epoch: 0320 loss_train: 0.9089 time: 0.6993s\n",
      "Epoch: 0321 loss_train: 0.7275 time: 0.6959s\n",
      "Epoch: 0322 loss_train: 0.8730 time: 0.6811s\n",
      "Epoch: 0323 loss_train: 0.7344 time: 0.6137s\n",
      "Epoch: 0324 loss_train: 0.6945 time: 0.7454s\n",
      "Epoch: 0325 loss_train: 1.2436 time: 0.6362s\n",
      "Epoch: 0326 loss_train: 0.9162 time: 0.7792s\n",
      "Epoch: 0327 loss_train: 0.8555 time: 0.6072s\n",
      "Epoch: 0328 loss_train: 0.7251 time: 0.7296s\n",
      "Epoch: 0329 loss_train: 0.8246 time: 0.7557s\n",
      "Epoch: 0330 loss_train: 0.6963 time: 0.5877s\n",
      "Epoch: 0331 loss_train: 1.2185 time: 0.7773s\n",
      "Epoch: 0332 loss_train: 0.7507 time: 0.7373s\n",
      "Epoch: 0333 loss_train: 0.8118 time: 0.7053s\n",
      "Epoch: 0334 loss_train: 0.8704 time: 0.7571s\n",
      "Epoch: 0335 loss_train: 1.0262 time: 0.6608s\n",
      "Epoch: 0336 loss_train: 0.8481 time: 0.8014s\n",
      "Epoch: 0337 loss_train: 0.7375 time: 0.6572s\n",
      "Epoch: 0338 loss_train: 0.9194 time: 0.7177s\n",
      "Epoch: 0339 loss_train: 0.8223 time: 0.6951s\n",
      "Epoch: 0340 loss_train: 1.0880 time: 0.5943s\n",
      "Epoch: 0341 loss_train: 0.8023 time: 0.5499s\n",
      "Epoch: 0342 loss_train: 0.7576 time: 0.5660s\n",
      "Epoch: 0343 loss_train: 0.8073 time: 0.5305s\n",
      "Epoch: 0344 loss_train: 0.9632 time: 0.6687s\n",
      "Epoch: 0345 loss_train: 0.7629 time: 0.6247s\n",
      "Epoch: 0346 loss_train: 1.2236 time: 0.6643s\n",
      "Epoch: 0347 loss_train: 0.7417 time: 0.5850s\n",
      "Epoch: 0348 loss_train: 0.7353 time: 0.7235s\n",
      "Epoch: 0349 loss_train: 0.8549 time: 0.5671s\n",
      "Epoch: 0350 loss_train: 0.9073 time: 0.6551s\n",
      "Epoch: 0351 loss_train: 0.8868 time: 0.5938s\n",
      "Epoch: 0352 loss_train: 1.2313 time: 0.6448s\n",
      "Epoch: 0353 loss_train: 1.0632 time: 0.6932s\n",
      "Epoch: 0354 loss_train: 0.9385 time: 0.6128s\n",
      "Epoch: 0355 loss_train: 1.2695 time: 0.6493s\n",
      "Epoch: 0356 loss_train: 0.9118 time: 0.6346s\n",
      "Epoch: 0357 loss_train: 1.1026 time: 0.6034s\n",
      "Epoch: 0358 loss_train: 0.6891 time: 0.7434s\n",
      "Epoch: 0359 loss_train: 0.7534 time: 0.6443s\n",
      "Epoch: 0360 loss_train: 1.2531 time: 0.6000s\n",
      "Epoch: 0361 loss_train: 0.9335 time: 0.6701s\n",
      "Epoch: 0362 loss_train: 0.7106 time: 0.6520s\n",
      "Epoch: 0363 loss_train: 0.8463 time: 0.6548s\n",
      "Epoch: 0364 loss_train: 0.9895 time: 0.8156s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0365 loss_train: 0.8311 time: 0.8546s\n",
      "Epoch: 0366 loss_train: 0.7179 time: 0.6802s\n",
      "Epoch: 0367 loss_train: 1.4436 time: 0.8814s\n",
      "Epoch: 0368 loss_train: 1.0275 time: 0.6056s\n",
      "Epoch: 0369 loss_train: 0.8757 time: 0.9889s\n",
      "Epoch: 0370 loss_train: 0.9085 time: 0.7889s\n",
      "Epoch: 0371 loss_train: 1.1653 time: 0.9158s\n",
      "Epoch: 0372 loss_train: 0.9626 time: 0.6580s\n",
      "Epoch: 0373 loss_train: 0.9525 time: 0.5892s\n",
      "Epoch: 0374 loss_train: 0.7999 time: 0.6812s\n",
      "Epoch: 0375 loss_train: 0.6928 time: 0.8780s\n",
      "Epoch: 0376 loss_train: 0.9036 time: 0.9413s\n",
      "Epoch: 0377 loss_train: 0.8122 time: 0.7388s\n",
      "Epoch: 0378 loss_train: 1.1653 time: 0.7100s\n",
      "Epoch: 0379 loss_train: 0.7949 time: 0.9110s\n",
      "Epoch: 0380 loss_train: 1.3154 time: 0.7129s\n",
      "Epoch: 0381 loss_train: 1.0556 time: 0.6323s\n",
      "Epoch: 0382 loss_train: 0.7833 time: 0.5671s\n",
      "Epoch: 0383 loss_train: 0.7647 time: 0.5942s\n",
      "Epoch: 0384 loss_train: 0.6806 time: 0.5676s\n",
      "Epoch: 0385 loss_train: 0.6458 time: 0.6428s\n",
      "Epoch: 0386 loss_train: 0.6788 time: 0.5362s\n",
      "Epoch: 0387 loss_train: 0.8274 time: 0.5510s\n",
      "Epoch: 0388 loss_train: 0.8315 time: 0.5467s\n",
      "Epoch: 0389 loss_train: 0.9958 time: 0.9680s\n",
      "Epoch: 0390 loss_train: 0.7070 time: 0.9193s\n",
      "Epoch: 0391 loss_train: 0.7126 time: 0.9730s\n",
      "Epoch: 0392 loss_train: 0.8995 time: 0.7695s\n",
      "Epoch: 0393 loss_train: 0.7986 time: 0.6653s\n",
      "Epoch: 0394 loss_train: 0.7546 time: 0.5626s\n",
      "Epoch: 0395 loss_train: 0.7148 time: 0.5794s\n",
      "Epoch: 0396 loss_train: 0.6906 time: 0.7010s\n",
      "Epoch: 0397 loss_train: 0.8032 time: 0.6579s\n",
      "Epoch: 0398 loss_train: 1.1237 time: 0.5868s\n",
      "Epoch: 0399 loss_train: 0.7062 time: 0.9806s\n",
      "Epoch: 0400 loss_train: 1.3882 time: 0.8169s\n",
      "Epoch: 0401 loss_train: 0.6747 time: 0.7211s\n",
      "Epoch: 0402 loss_train: 0.6984 time: 0.8138s\n",
      "Epoch: 0403 loss_train: 0.7108 time: 0.7013s\n",
      "Epoch: 0404 loss_train: 0.9653 time: 0.6862s\n",
      "Epoch: 0405 loss_train: 0.7791 time: 0.5804s\n",
      "Epoch: 0406 loss_train: 1.1447 time: 0.5156s\n",
      "Epoch: 0407 loss_train: 0.7780 time: 0.8723s\n",
      "Epoch: 0408 loss_train: 0.7244 time: 0.6646s\n",
      "Epoch: 0409 loss_train: 0.6755 time: 0.9648s\n",
      "Epoch: 0410 loss_train: 0.9469 time: 0.5955s\n",
      "Epoch: 0411 loss_train: 0.8990 time: 0.7006s\n",
      "Epoch: 0412 loss_train: 0.8031 time: 0.7760s\n",
      "Epoch: 0413 loss_train: 0.7328 time: 0.5877s\n",
      "Epoch: 0414 loss_train: 0.9383 time: 0.7445s\n",
      "Epoch: 0415 loss_train: 0.7945 time: 0.8320s\n",
      "Epoch: 0416 loss_train: 0.6680 time: 1.0551s\n",
      "Epoch: 0417 loss_train: 1.0255 time: 1.1807s\n",
      "Epoch: 0418 loss_train: 0.7989 time: 0.9064s\n",
      "Epoch: 0419 loss_train: 1.2176 time: 0.9112s\n",
      "Epoch: 0420 loss_train: 1.0253 time: 1.0895s\n",
      "Epoch: 0421 loss_train: 0.8651 time: 1.0211s\n",
      "Epoch: 0422 loss_train: 1.0608 time: 1.0245s\n",
      "Epoch: 0423 loss_train: 0.6932 time: 0.9106s\n",
      "Epoch: 0424 loss_train: 0.7532 time: 1.0398s\n",
      "Epoch: 0425 loss_train: 0.6184 time: 0.6136s\n",
      "Epoch: 0426 loss_train: 0.7340 time: 0.7734s\n",
      "Epoch: 0427 loss_train: 0.6896 time: 0.5614s\n",
      "Epoch: 0428 loss_train: 0.7608 time: 0.7539s\n",
      "Epoch: 0429 loss_train: 0.8147 time: 0.5897s\n",
      "Epoch: 0430 loss_train: 0.7933 time: 0.4689s\n",
      "Epoch: 0431 loss_train: 1.1183 time: 0.6348s\n",
      "Epoch: 0432 loss_train: 0.8279 time: 0.5914s\n",
      "Epoch: 0433 loss_train: 0.9115 time: 0.4858s\n",
      "Epoch: 0434 loss_train: 0.7698 time: 0.6924s\n",
      "Epoch: 0435 loss_train: 0.8331 time: 0.9423s\n",
      "Epoch: 0436 loss_train: 0.8447 time: 1.0842s\n",
      "Epoch: 0437 loss_train: 1.0605 time: 1.2260s\n",
      "Epoch: 0438 loss_train: 0.6745 time: 0.8919s\n",
      "Epoch: 0439 loss_train: 1.1360 time: 0.8877s\n",
      "Epoch: 0440 loss_train: 0.9658 time: 0.8585s\n",
      "Epoch: 0441 loss_train: 1.2131 time: 1.0596s\n",
      "Epoch: 0442 loss_train: 0.9785 time: 0.7763s\n",
      "Epoch: 0443 loss_train: 0.8631 time: 0.7434s\n",
      "Epoch: 0444 loss_train: 0.8745 time: 0.9694s\n",
      "Epoch: 0445 loss_train: 0.8629 time: 0.8916s\n",
      "Epoch: 0446 loss_train: 0.8607 time: 0.7639s\n",
      "Epoch: 0447 loss_train: 0.9561 time: 0.7372s\n",
      "Epoch: 0448 loss_train: 0.8908 time: 0.6484s\n",
      "Epoch: 0449 loss_train: 1.0696 time: 0.8852s\n",
      "Epoch: 0450 loss_train: 0.6751 time: 0.7933s\n",
      "Epoch: 0451 loss_train: 0.7467 time: 0.7755s\n",
      "Epoch: 0452 loss_train: 1.0938 time: 0.5649s\n",
      "Epoch: 0453 loss_train: 1.3254 time: 0.8495s\n",
      "Epoch: 0454 loss_train: 1.0228 time: 0.9358s\n",
      "Epoch: 0455 loss_train: 0.7422 time: 0.9341s\n",
      "Epoch: 0456 loss_train: 0.7544 time: 0.8372s\n",
      "Epoch: 0457 loss_train: 1.0680 time: 0.9489s\n",
      "Epoch: 0458 loss_train: 0.7706 time: 0.8919s\n",
      "Epoch: 0459 loss_train: 0.7440 time: 1.0374s\n",
      "Epoch: 0460 loss_train: 0.8887 time: 0.9204s\n",
      "Epoch: 0461 loss_train: 0.6958 time: 0.8748s\n",
      "Epoch: 0462 loss_train: 0.8690 time: 0.8392s\n",
      "Epoch: 0463 loss_train: 0.8437 time: 0.7781s\n",
      "Epoch: 0464 loss_train: 0.8736 time: 0.8721s\n",
      "Epoch: 0465 loss_train: 0.6485 time: 0.8570s\n",
      "Epoch: 0466 loss_train: 0.8493 time: 0.7572s\n",
      "Epoch: 0467 loss_train: 0.7995 time: 0.8197s\n",
      "Epoch: 0468 loss_train: 0.8132 time: 0.6887s\n",
      "Epoch: 0469 loss_train: 0.7218 time: 0.9837s\n",
      "Epoch: 0470 loss_train: 0.9594 time: 0.7155s\n",
      "Epoch: 0471 loss_train: 0.9984 time: 0.7066s\n",
      "Epoch: 0472 loss_train: 0.6897 time: 0.8294s\n",
      "Epoch: 0473 loss_train: 0.9008 time: 0.7976s\n",
      "Epoch: 0474 loss_train: 1.0269 time: 0.7390s\n",
      "Epoch: 0475 loss_train: 1.1518 time: 0.7089s\n",
      "Epoch: 0476 loss_train: 0.8846 time: 0.7823s\n",
      "Epoch: 0477 loss_train: 0.7850 time: 0.7130s\n",
      "Epoch: 0478 loss_train: 0.9440 time: 0.7890s\n",
      "Epoch: 0479 loss_train: 0.8616 time: 0.8514s\n",
      "Epoch: 0480 loss_train: 0.7507 time: 0.8135s\n",
      "Epoch: 0481 loss_train: 1.0735 time: 0.6000s\n",
      "Epoch: 0482 loss_train: 0.9931 time: 0.8576s\n",
      "Epoch: 0483 loss_train: 0.6949 time: 0.7790s\n",
      "Epoch: 0484 loss_train: 0.9870 time: 0.7934s\n",
      "Epoch: 0485 loss_train: 0.6855 time: 0.8289s\n",
      "Epoch: 0486 loss_train: 0.6631 time: 0.7946s\n",
      "Epoch: 0487 loss_train: 0.7467 time: 0.6095s\n",
      "Epoch: 0488 loss_train: 0.8649 time: 0.8015s\n",
      "Epoch: 0489 loss_train: 0.8465 time: 1.0050s\n",
      "Epoch: 0490 loss_train: 0.7194 time: 0.7932s\n",
      "Epoch: 0491 loss_train: 0.6967 time: 0.7022s\n",
      "Epoch: 0492 loss_train: 0.7225 time: 0.8316s\n",
      "Epoch: 0493 loss_train: 0.6599 time: 0.7442s\n",
      "Epoch: 0494 loss_train: 1.0944 time: 0.8084s\n",
      "Epoch: 0495 loss_train: 0.8055 time: 0.7220s\n",
      "Epoch: 0496 loss_train: 0.7078 time: 0.8376s\n",
      "Epoch: 0497 loss_train: 0.9808 time: 0.7672s\n",
      "Epoch: 0498 loss_train: 0.8934 time: 0.7907s\n",
      "Epoch: 0499 loss_train: 0.7942 time: 0.6886s\n",
      "Epoch: 0500 loss_train: 0.8042 time: 0.8599s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 359.4269s\n",
      "Test set results: loss= 0.8288 accuracy= 0.6471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def save_plot(embedding, edges, labels, epoch):\n",
    "    X = np.array(embedding.detach().numpy())\n",
    "    X_tsne = X\n",
    "    \n",
    "    labelled =  X_tsne[[0,2,4,8]] \n",
    "\n",
    "\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(20, 20)\n",
    "    \n",
    "    axes = plt.gca()\n",
    "\n",
    "\n",
    "    color_map = {0:'red', 1:'green', 2:'blue', 3:'magenta', 4:'black', 5:'orange', 6:'pink'}\n",
    "    colors = [color_map[i] for i in labels.numpy()]\n",
    "\n",
    "    def connectpoints(x,y,p1,p2):\n",
    "        x1, x2 = x[p1], x[p2]\n",
    "        y1, y2 = y[p1], y[p2]\n",
    "        plt.plot([x1,x2],[y1,y2],'k-',alpha=0.2)\n",
    "\n",
    "    for edge in edges:\n",
    "        connectpoints(X_tsne.T[0], X_tsne.T[1], edge[0], edge[1])\n",
    "\n",
    "\n",
    "\n",
    "    plt.scatter(X_tsne.T[0], X_tsne.T[1], c = colors, alpha=0.5, s=200)\n",
    "    plt.scatter(labelled.T[0], labelled.T[1], c = 'grey', alpha=0.5, s=500)\n",
    "    plt.savefig('karate_club_figures/' + str(epoch) + '.jpg') # A karate_club_figures folder must be present for this to work ;)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    embedding, output = model(features, adj)\n",
    "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
    "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test.item()))\n",
    "\n",
    "\n",
    "\n",
    "t_total = time.time()\n",
    "for epoch in range(epochs):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    embedding, output = model(features, adj)\n",
    "    \n",
    "    save_plot(embedding, edges, labels, epoch)\n",
    "    \n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train])\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    embedding, output = model(features, adj)\n",
    "\n",
    "    loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
    "    acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "# Testing\n",
    "test()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
